(2.33*300/40)^2
(30.69-32)/(4.31/6)
?qnorm
pnorm(1.82,mean=0,sd=1)
pnorm(-1.82,mean=0,sd=1)
30.69+c(-1,1)*1.645*4.31/6
9.4/sqrt(507)
(1.96*300/25)^2
pnorm((134-130)/(17/sqrt(35)),mean=0,sd=1)
pnorm((134-130)/(17/sqrt(35)),mean=0,sd=1,lower.tail=TRUE)
pnorm((134-130)/(17/sqrt(35)),mean=0,sd=1,lower.tail=FALSE)
415+c(-1,1)*220/sqrt(100)
415+c(-1,1)*1.96*220/sqrt(100)
q()
pop_mean <- 10
sam_mean <- 9.51
sd <- 4.65
n <- 40
z <- (pop_mean-sam_mean)/(sd/sqrt(n))
pnorm(z)
z <- (sam_mean-pop_mean)/(sd/sqrt(n))
pnorm(z)
0.91*0.02+0.09*0.9
0.09*0.9/0.0992
(9/2)^2
(1.28*18/4)^2
q()
0.0499-0.0364
0.5*0.5/(0.01/1.96)^2
q()
104*(15/104)
104*(89/104)
sqrt(0.36*0.64/50)
26*7/50
24*7/50
150*0.08
150*0.05
q()
76
76+0.35*72+0.43*30
qt(0.025,df=394)
q()
sum(dbinom(4:20,20,0.1))
dbinom(2,5,0.2)
dbinom(1,5,0.2)
dbinom(2,10,0.1)
dbinom(2,10,0.2)
q()
sqrt(0.11*0.89/100)
1.96*0.03+0.11
1-0.88^4
195528-1627
1627/828
193901/2
(1627/828)/(193901/2)
1627/2
193901/828
813.5*234.18
813.5/234.18
pf(3.47,828,2,lower.tail=FALSE)
SE <- sqrt(p(1-p)/3226)
p <- 0.2
SE <- sqrt(p(1-p)/3226)
SE <- sqrt(p*(1-p)/3226)
p <- 0.24
SE
SE <- sqrt(p*(1-p)/3226)
10/0.64
10/0.36
440*331/1293
46*112/625
0.05*0.93/(0.05*0.93+0.95*0.03)
1-((3819.99/15079.02)*(251/243))
q()
1.54/10000
0.08/10000
(0.08/10000)*100
q()
library(datasets)
data(mtcars)
tapply(mtcars$mpg, mtcars$cyl, mean)
lapply(mtcars, mean)
apply(mtcars, 2, mean)
tapply(mtcars$mpg, mtcars$cyl, mean)
split(mtcars, mtcars$cyl)
sapply(mtcars, cyl, mean)
with(mtcars, tapply(mpg, cyl, mean))
q()
3999+880*2
quit()
q()
install.packages("AppliedPredictiveModeling")
install.packages("caret")
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
indexTrain <- segmentationOriginal$Case == "Train"
train <- segmentationOriginal[indexTrain, ]
test <- segmentationOriginal[-indexTrain, ]
set.seed(125)
cartModel <- train(Class ~ ., data=train, method="rpart")
cartModel$finalModel
plot(cartModel$finalModel, uniform=T)
text(cartModel$finalModel, cex=0.8)
```
install.packages("pgmm")
library(pgmm)
data(olive)
olive = olive[,-1]
treeModel <- train(Area ~ ., data=olive, method="rpart")
newdata = as.data.frame(t(colMeans(olive)))
predict(treeModel, newdata)
library(ElemStatLearn)
install.packages("ElemStatLearn")
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
modelRandomforest <- randomForest(y ~ ., data = vowel.train)
varImp(modelRandomforest)
library(caret)
modelRandomforest <- randomForest(y ~ ., data = vowel.train)
install.packages("randomForest")
library(randomForest)
modelRandomforest <- randomForest(y ~ ., data = vowel.train)
varImp(modelRandomforest)
varImportance <- varImp(modelRandomforest)
order(varImportance)
View(varImportance)
order(varImportance$Overall)
order(varImportance$row.names)
modelRandomforest <- train(y ~ ., data = vowel.train, method="rf")
varImp(modelRandomforest)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
modelRF <- train(y ~ ., data=vowel.train, method="rf")
modelGBM <- train(y ~ ., data=vowel.train, method="gbm")
predictRF <- predict(modelRF, vowel.test)
predGBM <- predict(modelGBM, vowel.test)
confusionMatrix(predictRF, vowel.test$y)
confusionMatrix(predGBM, vowel.test$y)
pred <- data.frame(predictRF, predGBM, y=vowel.test$y, agree=predictRF == predGBM)
View(pred)
set.seed(62433)
modelRF <- train(diagnosis ~ ., data=training, method="rf")
modelGBM <- train(diagnosis ~ ., data=training, method="gbm")
modelLDA <- train(diagnosis ~ ., data=training, method="lda")
predictRF <- predict(modelRF, testing)
predictGBM <- predict(modelGBM, testing)
predictLDA <- predict(modelLDA, testing)
stackedPredict <- data.frame(predictRF, predictGBM, predictLDA, diagnosis=testing$diagnosis)
modelStacked <- train(diagnosis ~., data=stackedPredict, method="rf")
predictStacked <- predict(modelStacked, testing)
confusionMatrix(predictRF, testing$diagnosis)
confusionMatrix(predictGBM, testing$diagnosis)
confusionMatrix(predictLDA, testing$diagnosis)
confusionMatrix(predictStacked, testing$diagnosis)
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
modelRF <- train(diagnosis ~ ., data=training, method="rf")
modelGBM <- train(diagnosis ~ ., data=training, method="gbm")
modelLDA <- train(diagnosis ~ ., data=training, method="lda")
predictRF <- predict(modelRF, testing)
predictGBM <- predict(modelGBM, testing)
predictLDA <- predict(modelLDA, testing)
stackedPredict <- data.frame(predictRF, predictGBM, predictLDA, diagnosis=testing$diagnosis)
modelStacked <- train(diagnosis ~., data=stackedPredict, method="rf")
predictStacked <- predict(modelStacked, testing)
confusionMatrix(predictRF, testing$diagnosis)
confusionMatrix(predictGBM, testing$diagnosis)
confusionMatrix(predictLDA, testing$diagnosis)
confusionMatrix(predictStacked, testing$diagnosis)
install.packages("lubridate")
library(lubridate)  # For year() function below
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
dat = read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
modelBats <- bats(tstrain)
predictBats <- forecast(modelBats, level=95, h=dim(testing)[1])
install.packages("forecast")
modelBats <- bats(tstrain)
library(forecast)
modelBats <- bats(tstrain)
dim(testing)
dim(testing)[1]
nrow(testing)
predictBats <- forecast(modelBats, level=95, h=nrow(testing))
predictBats
combination <- data.frame(testing, predictBats)
View(combination)
combination$withinFlag <- combination$Lo.95<combination$visitsTumblr<combination$Hi.95
combination$withinFlag <- (combination$Lo.95<combination$visitsTumblr)&(combination$visitsTumblr<combination$Hi.95)
counts <- table(combination$withinFlag)
counts
prop.table(counts)
prop.table(counts)[2]
install.packages("e1071")
install.packages("e1071")
set.seed(325)
library(e1071)
modelSVM <- svm(CompressiveStrength ~., data=training)
library(e1071)
install.packages("e1071")
install.packages("e1071")
library(e1071)
modelSVM <- svm(CompressiveStrength ~., data=training)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
library(caret)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
library(e1071)
modelSVM <- svm(CompressiveStrength ~., data=training)
predictSVM <- predict(modelSVM, testing)
accuracySVM <- accuracy(predictSVM, testing$CompressiveStrength)
library(ElemStatLearn)
library(gbm)
accuracySVM <- accuracy(predictSVM, testing$CompressiveStrength)
library(forecast)
accuracySVM <- accuracy(predictSVM, testing$CompressiveStrength)
accuracySVM
set.seed(233)
modelLasso <- train(CompressiveStrength ~ ., data=training, method="lasso")
library(elasticnet)
modelLasso <- train(CompressiveStrength ~ ., data=training, method="lasso")
quit()
library(VIM)
str(sleep)
summary(sleep)
aggr(sleep, combined=T, numbers=T, prop=F, main='Missing Pattern of Sleep', ylab='')
indexInt <- sapply(sleep, is.integer)
sleepIntVar <- sleep[, indexInt]
sleepNumVar <- sleep[, !indexInt]
autoMfrow <- function(n){
if (n%2==0){
par(mfrow=c((n)/2,2))
}else{
par(mfrow=c((n+1)/2,2))
}
}
autoMfrow <- function(n) {
if (n%2==0){
par(mfrow=c((n)/2,2))
} else{
par(mfrow=c((n+1)/2,2))
}
}
autoMfrow <- function(numCnt) {
if (numCnt%2==0){
par(mfrow=c((numCnt)/2,2))
} else{
par(mfrow=c((numCnt+1)/2,2))
}
}
autoMfrow <- function(x){
if (x%%2==0){
par(mfrow=c((x)/2,2))
} else{
par(mfrow=c((x+1)/2,2))
}
}
numCnt <- ncol(sleepNumVar)
autoMfrow(numCnt)
quit()
library(VIM)
matrixplot(sleep)
quit()
quit()
fig_caption: false
x <- c(0.61, 0.93, 0.83, 0.35, 0.54, 0.16, 0.91, 0.62, 0.62)
y <- c(0.67, 0.84, 0.6, 0.18, 0.85, 0.47, 1.1, 0.65, 0.36)
fit <- lm(y~x)
summary(fit)
coef(fit)
residual <- resid(fit)
squaredResidual <- residual^2
residualVariance <- sum(squaredResidual) / (length(residual) - 2)
sqrt(residualVariance)
data(mtcars)
fit <- lm(mpg ~ wt, mtcars)
summary(fit)
fit$sd
fit$coef
summary(fit)$coef
summary(fit)$coef[,2]
summary(fit)$coef[,2][2]
summary(fit)$coef[,2][2]
exp <- fit$coef[1] + mean(wt) * fit$coef[2]
exp - 2 * summary(fit)$coef[,2][2]
exp <- fit$coef[1] + mean(mtcars$wt) * fit$coef[2]
exp - 2 * summary(fit)$coef[,2][2]
exp <- fit$coef[1] + mean(mtcars$wt) * fit$coef[2]
summary(fit)$coef[,2][2][1]
exp <- fit$coef[1] + mean(mtcars$wt) * fit$coef[2]
summary(fit)$coef[,2][2][2]
exp <- fit$coef[1] + mean(mtcars$wt) * fit$coef[2]
str(summary(fit)$coef[,2][2])
exp <- fit$coef[1] + mean(mtcars$wt) * fit$coef[2]
type(summary(fit)$coef[,2][2])
typeof(summary(fit)$coef[,2][2])
exp - 2 * 0.5591
?mtcars
fit[[1]][1] + 3 * fit[[1]][2]
fit[[1]]
fit[[1]][1]
fit[[1]][1] + fit[[1]][2]*(3000/1000)
fit[[1]][1] + fit[[1]][2]*(3000/1000)
fit[[1]][1] + fit[[1]][2]*(3000/1000)
2 * (fit$coef[2] - 2 * summary(fit)$coef[,2][2])
2 * (fit$coef[2] - (2000/1000) * summary(fit)$coef[,2][2])
(fit$coef[2] - (2000/1000) * summary(fit)$coef[,2][2])
b1+c(1,-1)*qt(p = 0.975, df = fit$df)*summary(fit)$coef[,2][2]
summary(fit)$coef[,2]+c(1,-1)*qt(p = 0.975, df = fit$df)*summary(fit)$coef[,2][2]
summary(fit)$coef[,2][2]+c(1,-1)*qt(p = 0.975, df = fit$df)*summary(fit)$coef[,2][2]
summary(fit)
(2000/1000) * (fit$coef[2] - 2 * summary(fit)$coef[,2][2])
I have an outcome, $Y$, and a predictor, $X$ and fit a linear regression model with $\Y=beta_0+beta_1X+epsilon$Ïµ to obtaain $beta_0$ and $beta_1$. What would be the consequence to the subsequent slope and intercept if I were to refit the model with a new regressor, $X+c$ for some constant, $c$?
attributes(fit)
squaredResiduals <- fit$residuals ^ 2
squaredResiduals <- fit$residuals ^ 2
fitCompared <- lm(mpg ~ 1, mtcars)
squaredComparedResiduals <- fitCompared$residuals ^ 2
sum(squaredResiduals)/sum(squaredComparedResiduals)
Refer back to the `mtcars` data set with mpg as an outcome and weight (wt) as the predictor. About what is the ratio of the the sum of the squared errors, $\sum_{i=1}^{n} (Y_i-\hat\Y_i)^2$ when comparing a model with just an intercept (denominator) to the model with the intercept and slope (numerator)?
fit[[1]][1] + fit[[1]][2]*(3000/1000)
data(mtcars)
attach(mtcars)
fit <- lm(mpg ~ factor(cyl) + wt, mtcars)
summary(fit)$coef[3, 1]
summary(fit)
summary(fit)$coef
fitUnadjusted <- lm(mpg ~ cyl, mtcars)
summary(fitUnadjusted)$coef
fitUnadjusted <- lm(mpg ~ factor(cyl), mtcars)
summary(fitUnadjusted)$coef
fitNonInteraction <- lm(mpg ~ cyl + wt, mtcars)
summary(fitNonInteraction)$adj.r.squared
fitInteraction <- lm(mpg ~ cyl + wt + cyl:wt, mtcars)
summary(fitInteraction)$adj.r.squared
fitNonInteraction <- lm(mpg ~ factor(cyl) + wt, mtcars)
summary(fitNonInteraction)$adj.r.squared
fitInteraction <- lm(mpg ~ factor(cyl) + wt + factor(cyl):wt, mtcars)
summary(fitInteraction)$adj.r.squared
library(lmtest)
lrtest(fit_interaction, fit_non_interaction)
lrtest(fitInteraction, fitNonInteraction)
fit <- lm(mpg ~ I(wt * 0.5) + factor(cyl), data = mtcars)
summary(fit)$coef
x <- c(0.586, 0.166, -0.042, -0.614, 11.72)
y <- c(0.549, -0.026, -0.127, -0.751, 1.344)
fit <- lm(y ~ x)
max(hatvalues(fit))
influence.measures(fit)$infmat[5, 'dfb.x']
data(mtcars)
mtcars$cyl <- factor(mtcars$cyl)
mtcars$vs <- factor(mtcars$vs)
mtcars$am <- factor(mtcars$am)
mtcars$gear <- factor(mtcars$gear)
mtcars$carb <- factor(mtcars$carb)
str(mtcars)
library(ggplot2)
ggplot(mtcars, aes(x=am, y=mpg, fill=transmission)) +
geom_boxplot() +
xlab("Transmission type") +
ylab("Miles per gallon")
ggplot(mtcars, aes(x=am, y=mpg, fill=am)) +
geom_boxplot() +
xlab("Transmission type") +
ylab("Miles per gallon")
pairs(mtcars, panel = panel.smooth, main = "Pairs graph for MTCars")
fitUnivariate <- lm(mpg ~ am, data=mtcars)
summary(fitUnivariate)
summary(fitUnivariate)$r.squared*100%
summary(fitUnivariate)$r.squared*100%
summary(fitUnivariate)$r.squared
summary(fitUnivariate)$r.squared*100
round(summary(fitUnivariate)$r.squared*100, digits=2)
pairs(mtcars, panel=panel.smooth, main="Pair Graph of mtcars")
fitMultivariate <- lm(mpg ~ ., data=mtcars)
fitStepwise <- step(fitMultivariate, direction="both", trace=0)
summary(fitStepwise)
par(mfrow = c(2,2))
plot(fitStepwise)
summary(fitStepwise)$coef[6]
summary(fitStepwise)$coef[6,"Pr(>|t|)"]
head(mtcars)
round(summary(fitUnivariate)$r.squared*100, digits=2)
round(summary(fitStepwise)$r.squared*100, digits=2)#R-squared
summary(fitStepwise)$coef[6,"Pr(>|t|)"]#alpha
abs(fitStepwise$coef[2])
abs(fitStepwise$coef[3])
abs(fitStepwise$coef[4])
abs(fitStepwise$coef[5])
c(abs(fitStepwise$coef[2]), abs(fitStepwise$coef[3]), abs(fitStepwise$coef[4]), abs(fitStepwise$coef[5]))
library(MASS)
data(shuttle)
fit <- glm(use ~ wind, family='binomial', shuttle)
exp(fit$coeff)
fit$coeff
fit$coeff[2]
exp(fit$coeff)[2]
exp(fit$coeff)[2]
digit(exp(fit$coeff)[2],3)
round(exp(fit$coeff)[2],3)
exp(fit$coeff)
fit2 <- glm(use ~ wind + as.factor(magn), family='binomial', shuttle)
round(exp(fit2$coeff)[2],3)
fit2 <- glm(use ~ wind + magn, family='binomial', shuttle)
round(exp(fit2$coeff)[2],3)
exp(fit2$coeff)[2]
round(exp(fit2$coeff)[2],3)
fit1 <- glm(use ~ wind + magn, data = shuttle, family=binomial)
df <- shuttle
df$use <- relevel(shuttle$use,"noauto")
fit2 <- glm(use ~ wind + magn, data = df, family=binomial)
summary(fit1)
summary(fit2)
fit1$coeff
fit2$coeff
fit1 <- glm(use ~ wind + magn, data = shuttle, family=binomial)
shuttle2 <- shuttle
shuttle2$use <- relevel(shuttle2$use,"noauto")
fit2 <- glm(use ~ wind + magn, data = shuttle2, family=binomial)
fit1$coeff
fit2$coeff
data(InsectSprays)
fit <- glm(count ~ spray, data=InsectSprays, family=poisson)
exp(fit$coefficients[1])/exp(fit$coefficients[1]+fit$coefficients[2])
round(exp(fit$coefficients[1])/exp(fit$coefficients[1]+fit$coefficients[2]), 4)
InsectSprays$t <- seq(1:nrow(InsectSprays))
InsectSprays$t2 <- log(10) + InsectSprays$t
fit <- glm(count ~ spray + offset(t), data=InsectSprays, family=poisson)
fitT <- glm(count ~ spray + offset(t2), data=InsectSprays, family=poisson)
fit$coeff
fitT$coeff
x <- -5:5
y <- c(5.12, 3.93, 2.67, 1.87, 0.52, 0.08, 0.93, 2.05, 2.54, 3.87, 4.97)
d1 <- c(0, 0 ,0, 0, 0,  0,  1 , 1,  1 , 1 , 1)
d2 <- c(1, 1 ,1, 1, 1,  1,  0 , 0,  0, 0 , 0)
fit <- lm(y ~ d1*x))
fit <- lm(y ~ d1*x)
summary(fit)
fit$coeff
fit$coefficients[2]+fit$coefficients[3]
knots <- c(0)
splineTerms <- sapply(knots, function(knot) (x>0)*(x-knot))
xMat <- cbind(x,splineTerms)
fit <- lm(y ~ xMat)
yhat <- predict(fit)
summary(fit)
plot(x,y,frame = FALSE, pch = 21, bg = 'lightblue',cex=2)
lines(x,yhat,col='red',lwd=2)
# slope is
fit$coefficients[2]+fit$coefficients[3]
knots <- c(0)
splineTerms <- sapply(knots, function(knot) (x>0)*(x-knot))
xMat <- cbind(x,splineTerms)
fit <- lm(y ~ xMat)
yhat <- predict(fit)
fit$coefficients[2]+fit$coefficients[3]
round(fit$coefficients[2]+fit$coefficients[3],3)
library(MASS)
quit()
shinyapps::setAccountInfo(name='yaojenkuo', token='C78DF668EE134F538EC050A2DA6CEDA7', secret='9JpGahAHVlmIRP1CYp9wApTCB/YFckvcMnsgefrC')
shiny::runApp('ApplicationInR/quakesTW')
library(shiny)
library(rsconnect)
deployApp()
q()
#Islamic State Attacks in 2015
#Source: BBC
# Preparing the data from BBC
date <- c('2015-11-13', '2015-11-12', '2015-10-31', '2015-10-10', '2015-07-18', '2015-06-26', '2015-06-26', '2015-05-22', '2015-03-21','2015-03-18')
#country <- c('France', 'Lebanon', 'Egypt', 'Turkey', 'Tunisia', 'Iraq', 'Kuwait', 'Saudi Arabia', 'Yemen', 'Tunisia')
state <- c('Paris', 'Beirut', 'Janub Sina\'', 'Ankara', 'Sousse', 'Diyala', 'Al Asimah', 'Ash Sharqiyah', 'Sana\'a', 'Tunis')
city <- c('Paris', 'Beirut', 'Sharm el Sheikh', 'Ankara', 'Sousse', 'Khan Bani Saad', 'Kuwait City', 'Qatif', 'Sana\'a', 'Tunis City')
deaths <- c(129, 43, 224, 102, 38, 125, 27, 21, 137, 19)
ISAttacks2015 <- data.frame(date, state, city, deaths, stringsAsFactors=FALSE)
ISAttacks2015$date <- as.Date(ISAttacks2015$date, "%Y-%m-%d")#Y for 4-digit
setwd("C:/Users/ASUS/Documents/ApplicationInR/ISAttacks2015/states")
# Load required packages
library(rgdal) # to read Shapefile
library(rgeos) # to simplify Shapefile
library(geojsonio) # to write GeoJSON
library(maptools) # to read Shapefile
# Read Shapefile of states from C:/ApplicationInR/ISAttacks2015/states
stateShp <- readShapePoly('states/ne_10m_admin_1_states_provinces.shp')
# Subset Shapefile with attacked states
stateShpSubset <- stateShp[stateShp$name %in% c('Paris', 'Beirut', 'Janub Sina\'', 'Ankara', 'Sousse', 'Diyala', 'Al Asimah', 'Ash Sharqiyah', 'Sana\'a', 'Tunis'),]
# Simplify attacked states
stateShpSimplify <- gSimplify(stateShpSubset,tol=0.005, topologyPreserve=TRUE)
