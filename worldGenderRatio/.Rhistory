binwidth=0.5,
colour="black", fill="antiquewhite")+
geom_density(alpha=0.02, fill="#EEEEEE")
}
normalPlot(400)
# How to draw a normal distribution plot
normalPlot <- function(sampleSize){
set.seed(1)
rating <- rnorm(sampleSize)
data <- data.frame(rating)
head(data)
ggplot(data, aes(x=rating))+
geom_histogram(aes(y=..density..),
binwidth=0.3,
colour="black", fill="antiquewhite")+
geom_density(alpha=0.02, fill="#EEEEEE")
}
normalPlot(400)
normalPlot(80000)
normalPlot(80000)
ls()
normalPlot(8000)
q()
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
install.packages("caret")
library(caret)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis, p = 0.50,list=FALSE)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
xnames <- colnames(concrete)[1:8]
featurePlot(x=training[, xnames], y=training$CompressiveStrength, plot="pairs")
data(concrete)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
xnames <- colnames(concrete)[1:8]
featurePlot(x=training[, xnames], y=training$CompressiveStrength, plot="pairs")
ggplot(data=training, aes(x=Superplasticizer)) + geom_histogram() + theme_bw()
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
ss <- training[,grep('^IL', x = names(training) )]
preProc <- preProcess(ss, method='pca', thresh=0.9,
outcome=training$diagnosis)
preProc$rotation
set.seed(3433)
IL <- grep("^IL", colnames(training), value=TRUE)
ILpredictors <- predictors[, IL]
df <- data.frame(diagnosis, ILpredictors)
inTrain <- createDataPartition(df$diagnosis, p=3/4)[[1]]
training <- df[inTrain, ]
testing <- df[-inTrain, ]
modelFit <- train(diagnosis ~ ., method="glm", data=training)
predictions <- predict(modelFit, newdata=testing)
C1 <- confusionMatrix(predictions, testing$diagnosis)
print(C1)
acc1 <- C1$overall[1]
acc1 # Non-PCA Accuracy: 0.65
modelFit <- train(training$diagnosis ~ .,
method="glm",
preProcess="pca",
data=training,
trControl=trainControl(preProcOptions=list(thresh=0.8)))
C2 <- confusionMatrix(testing$diagnosis, predict(modelFit, testing))
print(C2)
acc2 <- C2$overall[1]
acc2 # PCA Accuracy: 0.72
quit()
library(car)
head(Quartet)
plot(Quartet$x, Quartet$y1)
lmfit = lm(y1~x, Quartet)
abline(lmfit, col="red")
summary(lmfit)
head(mtcars)
lm1  <-  glm(vs ~ hp,data=mtcars, family=binomial)
summary(lm1)
plot(mtcars$h1, mtcars$vs)
plot(mtcars$h1, mtcars$vs)
library(ggplot2)
ggplot(mtcars, aes(x=h1, y=vs)) + geom_point() +
stat_smooth(method="glm", family="binomial", se=FALSE)
plot(mtcars$hp, mtcars$vs)
curve(predict(lm1, data.frame(hp=x), type="response"), add=TRUE)
install.packages("ROCR")
library(ROCR)
pred <- prediction(predictions = sms_results$prob_spam,
labels = sms_results$actual_type)
data(sms_results)
perf <- performance(pred, measure = "tpr", x.measure = "fpr")
svmfit=svm(churn~ ., data=trainset, prob=TRUE)
head(trainset)
head(diamonds)
library(ggplot2)
diamonds$is_expensive <- diamonds$price > 2400
is_test <- runif(nrow(diamonds)) > 0.75
train <- diamonds[is_test==FALSE,]
test <- diamonds[is_test==TRUE,]
summary(fit <- glm(is_expensive ~ carat + cut + clarity, data=train))
diamonds$is_expensive <- diamonds$price > 2400
is_test <- runif(nrow(diamonds)) > 0.75
train <- diamonds[is_test==FALSE,]
test <- diamonds[is_test==TRUE,]
summary(fit1 <- glm(is_expensive ~ carat + cut + clarity, data=train))
summary(fit2 <- glm(is_expensive ~ carat, data=train))
library(ROCR)
prob1 <- predict(fit1, newdata=test, type="response")
pred1 <- prediction(prob1, test$is_expensive)
perf1 <- performance(pred1, measure = "tpr", x.measure = "fpr")
prob2 <- predict(fit2, newdata=test, type="response")
pred2 <- prediction(prob2, test$is_expensive)
perf2 <- performance(pred2, measure = "tpr", x.measure = "fpr")
auc1 <- performance(pred1, measure = "auc")
auc1 <- auc1@y.values[[1]]
auc2 <- performance(pred2, measure = "auc")
auc2 <- auc2@y.values[[1]]
summary(fit1 <- glm(is_expensive ~ carat + cut + clarity, data=train))
summary(fit2 <- glm(is_expensive ~ cut, data=train))
library(ROCR)
prob1 <- predict(fit1, newdata=test, type="response")
pred1 <- prediction(prob1, test$is_expensive)
perf1 <- performance(pred1, measure = "tpr", x.measure = "fpr")
prob2 <- predict(fit2, newdata=test, type="response")
pred2 <- prediction(prob2, test$is_expensive)
perf2 <- performance(pred2, measure = "tpr", x.measure = "fpr")
auc1 <- performance(pred1, measure = "auc")
auc1 <- auc1@y.values[[1]]
auc2 <- performance(pred2, measure = "auc")
auc2 <- auc2@y.values[[1]]
summary(fit1 <- glm(is_expensive ~ carat + cut + clarity, data=train))
summary(fit2 <- glm(is_expensive ~ clarity, data=train))
library(ROCR)
prob1 <- predict(fit1, newdata=test, type="response")
pred1 <- prediction(prob1, test$is_expensive)
perf1 <- performance(pred1, measure = "tpr", x.measure = "fpr")
prob2 <- predict(fit2, newdata=test, type="response")
pred2 <- prediction(prob2, test$is_expensive)
perf2 <- performance(pred2, measure = "tpr", x.measure = "fpr")
auc1 <- performance(pred1, measure = "auc")
auc1 <- auc1@y.values[[1]]
auc2 <- performance(pred2, measure = "auc")
auc2 <- auc2@y.values[[1]]
summary(fit1 <- glm(is_expensive ~ carat + cut + clarity, data=train))
summary(fit2 <- glm(is_expensive ~ cut, data=train))
library(ROCR)
prob1 <- predict(fit1, newdata=test, type="response")
pred1 <- prediction(prob1, test$is_expensive)
perf1 <- performance(pred1, measure = "tpr", x.measure = "fpr")
prob2 <- predict(fit2, newdata=test, type="response")
pred2 <- prediction(prob2, test$is_expensive)
perf2 <- performance(pred2, measure = "tpr", x.measure = "fpr")
auc1 <- performance(pred1, measure = "auc")
auc1 <- auc1@y.values[[1]]
auc2 <- performance(pred2, measure = "auc")
auc2 <- auc2@y.values[[1]]
plot(perf1, colorize = TRUE)
plot(perf2, add = TRUE, colorize = TRUE)
abline(a = 0, b = 1, lwd = 2, lty = 2)
quit()
ggplot(data=training, aes(x=Superplasticizer)) + geom_histogram()
library(ggplot2)
ggplot(data=training, aes(x=Superplasticizer)) + geom_histogram()
namesTraining <- names(training)
training = adData[ inTrain,]
adData = data.frame(diagnosis,predictors)
data(AlzheimerDisease)
install.packages("caret")
install.packages("AppliedPredictiveModeling")
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
namesTraining <- names(training)
predictorsIL <- grep('^IL', namesTraining)
predictorsILTrain <- training[,predictorsIL]
dataframeTrain <- data.frame(training$diagnosis, predictorsILTrain)
glmFit <- train(diagnosis ~ ., method="glm", data=dataframeTrain)
dataframeTrain <- data.frame(diagnosis, predictorsILTrain)
namesTraining <- names(training)
predictorsIL <- grep('^IL', namesTraining)
predictorsILTrain <- training[,predictorsIL]
dataframeTrain <- data.frame(diagnosis, predictorsILTrain)
dataframeTrain <- data.frame(training$diagnosis, predictorsILTrain)
View(dataframeTrain)
glmFit <- train(training.diagnosis ~ ., method="glm", data=dataframeTrain)
glmPredictions <- predict(glmFit, newdata=testing)
confusionMatrix(glmPredictions, testing$diagnosis)
pcaFit <- train(diagnosis ~ ., method="glm", preProcess="pca", data=predictorsILTrain, trainControl(preProcOptions=list(thresh=0.8)))
pcaFit <- train(training.diagnosis ~ ., method="glm", preProcess="pca", data=predictorsILTrain, trainControl(preProcOptions=list(thresh=0.8)))
pcaFit <- train(training.diagnosis ~ ., method="glm", preProcess="pca", data=dataframeTrain, trainControl(preProcOptions=list(thresh=0.8)))
pcaFit <- train(training.diagnosis ~ ., method="glm", preProcess="pca", data=dataframeTrain, trainControl(preProcOptions=list(thresh=0.8)))
trControl=trainControl(preProcOptions=list(thresh=0.8)))
pcaFit <- train(training.diagnosis ~ .,
method="glm",
preProcess="pca",
data=dataframeTrain, trControl=trainControl(preProcOptions=list(thresh=0.8)))
pcaPredictions <- predict(pcaFit, newdata=testing)
confusionMatrix(pcaPredictions, testing$diagnosis)
quit()
install.packages("VIM")
library(VIM)
head(sleep)
str(sleep)
table(sleep$Exp)
table(sleep$Pred)
table(sleep$Danger)
aggr(sleep, combined=T)
aggr(sleep, combined=T, numbers=T, main='Missing Pattern of Sleep', ylab='')
aggr(sleep, combined=T, numbers=T, freq=F, main='Missing Pattern of Sleep', ylab='')
aggr(sleep, combined=T, numbers=F, freq=F, main='Missing Pattern of Sleep', ylab='')
aggr(sleep, combined=T, numbers=T, prop=F, main='Missing Pattern of Sleep', ylab='')
is.numeric(sleep)
colclass(sleep)
lapply(sleep, class)
sleepVarClass <- lapply(sleep, class)
sleepVarClass
sleepVarClass[1]
sleepVarClass[[1]]
sleepVarClass[[1:9]]
sleepVarClass[[1]:[9]]
sleepVarClass[[9]]
sleepVarCon <- sleepVarClass[[,"numeric"]]
class(sleep)
sapply(sleep, class)
sapply(sleep, class)[1]
sapply(sleep, class)[[1]
]
length(sleepVarClass)
is.numeric(sleepVarClass)
is.numeric(sleepVarClass[1])
is.numeric(sleepVarClass[2])
is.numeric(sleepVarClass[3])
is.numeric(sleepVarClass[[3])
is.numeric(sleepVarClass[[3]])
is.numeric(sleepVarClass[[4]])
is.numeric(sleepVarClass[[5]])
indexNum <- lapply(sleep, is.numeric)
indexNum
sleepNumVar <- sleep[,indexNum]
indexNum <- sapply(sleep, is.numeric)
indexNum
sleepNumVar <- sleep[, indexNum]
View(sleepNumVar)
indexNum <- sapply(sleep, is.numeric)
sleepNumVar <- sleep[, indexNum]
indexNum <- sapply(sleep, is.int)
indexNum <- sapply(sleep, is.integer)
sleepNumVar <- sleep[, indexNum]
indexInt <- sapply(sleep, is.integer)
sleepIntVar <- sleep[, indexInt]
sleepIntVar <- sleep[, -indexInt]
indexInt <- sapply(sleep, is.integer)
sleepIntVar <- sleep[, indexInt]
sleepNumVar <- sleep[, -indexInt]
indexInt
sleepNumVar <- sleep[, !=indexInt]
sleepNumVar <- !sleep[, indexInt]
sleepNumVar <- sleep[, !indexInt]
length(indexInt)
ncol(sleepIntVar)
ncol(sleepNumVar)
if (numCnt%2==0){
par(mfrow=c(numCnt/2, 2))
}else{
par(mfrow=c((numCnt+1)/2, 2))
}
if (numCnt%2==0)
par(mfrow=c(numCnt/2, 2))
else par(mfrow=c((numCnt+1)/2, 2))
numCnt <- ncol(sleepNumVar)
if (numCnt%2==0){
par(mfrow=c(numCnt/2, 2))
}else{
par(mfrow=c((numCnt+1)/2, 2))
}
numCnt <- ncol(sleepNumVar)
par(mfrow=c((numCnt+1)/2,2))
numVarName <- names(sleepNumVar)
for (name in numVarName){
hist(sleepNumVar[,name],
freq=FALSE,
col="skyblue",
xlab=name,
ylab='',
main=paste("Histogram of: ", name))
lines(density(sleepNumVar[,name], na.rm=TRUE), lwd=2, col="red")
}
intCnt <- ncol(sleepIntVar)
par(mfrow=c((intCnt+1)/2,2))
intVarName <- names(sleepIntVar)
for (name in intVarName){
barplot(table(sleepIntVar[,name], exclude=NULL),
xlab=name,
main=paste("Barplot of: ", name))
}
table(sleep$Pred)
histNum <- hist(sleep$BrainWgt,
freq=FALSE,
col="skyblue",
xlab=name,
ylab='',
main=paste("Histogram of: ", name))
lines(density(sleep$BrainWgt, na.rm=TRUE), lwd=2, col="red")
histNum <- hist(sleep$BrainWgt,
freq=FALSE,
col="skyblue",
xlab=name,
ylab='',
main=paste("Histogram of: ", name))
lines(density(sleep$BrainWgt, na.rm=TRUE), lwd=2, col="red")
library(leaflet)
m <- leaflet()
m <- addTiles(m)
m
m <- leaflet()
m <- addTiles(m)
m <- addMarkers(m, lng=174.768, lat=-36.852, popup="The birthplace of R")
m
library(maps)
mapStates = map("state", fill = TRUE, plot = FALSE)
leaflet(data = mapStates) %>% addTiles() %>% addPolygons(fillColor = topo.colors(10, alpha = NULL), stroke = FALSE)
m = leaflet() %>% addTiles()
df = data.frame(
lat = rnorm(100),
lng = rnorm(100),
size = runif(100, 5, 20),
color = sample(colors(), 100)
)
m = leaflet(df) %>% addTiles()
m %>% addCircleMarkers(radius = ~size, color = ~color, fill = FALSE)
m %>% addCircleMarkers(radius = runif(100, 4, 10), color = c('red'))
m <- leaflet() %>% setView(lng = -71.0589, lat = 42.3601, zoom = 12)
m %>% addTiles()
m %>% addProviderTiles("Stamen.Toner")
m %>% addProviderTiles("Acetate.terrain")
m <- leaflet() %>% setView(lng = -71.0589, lat = 42.3601, zoom = 12)
m %>% addTiles()
m <- leaflet()
m <- addTiles(m)
m <- addMarkers(m, lng=174.768, lat=-36.852, popup="The birthplace of R")
m
m %>% addProviderTiles("Stamen.Toner")
m %>% addProviderTiles("Acetate.terrain")
m %>% addProviderTiles("CartoDB.Positron")
m <- leaflet() %>% setView(lng = -71.0589, lat = 42.3601, zoom = 12)
m %>% addProviderTiles("CartoDB.Positron")
data(quakes)
summary(quakes)
head(quakes)
leaflet(data = quakes[1:20,]) %>% addTiles() %>% addMarkers(~long, ~lat, popup = ~paste(as.character(depth),as.character(mag)))
leaflet(data = quakes[1:20,]) %>% addTiles() %>% addMarkers(~long, ~lat, popup = ~paste("Depth:",as.character(depth),",","Magnitude:",as.character(mag)))
cities <- read.csv(textConnection("
City,Lat,Long,Pop
Boston,42.3601,-71.0589,645966
Hartford,41.7627,-72.6743,125017
New York City,40.7127,-74.0059,8406000
Philadelphia,39.9500,-75.1667,1553000
Pittsburgh,40.4397,-79.9764,305841
Providence,41.8236,-71.4222,177994
"))
leaflet(cities) %>% addTiles() %>%
addCircles(lng = ~Long, lat = ~Lat, weight = 1,
radius = ~sqrt(Pop) * 30, popup = ~City
)
leaflet(cities) %>% addTiles() %>%
addCircles(lng = ~Long, lat = ~Lat, weight = 1,
radius = ~sqrt(Pop) * 30, popup = ~City
)
quit()
setwd("C:/ApplicationInR/worldGenderRatio")
# Load 'rgdal' library in R
library(rgdal)
# Download Shapefile
url.c <- 'http://www.naturalearthdata.com/http//www.naturalearthdata.com/download/10m/cultural/ne_10m_admin_0_countries.zip'
dfile <- ne_10m_admin_0_countries.zip'
download.file(url.c, destfile=dfile, method='wget')
# Unzip Shapefile
unzip('ne_10m_admin_0_countries.zip', exdir='countries')
#Remove .zip file
file.remove('ne_10m_admin_0_countries.zip')
# Read Shapefile of Countries
cshp <- readOGR('countries', 'ne_10m_admin_0_countries')
url.c <- 'http://www.naturalearthdata.com/http//www.naturalearthdata.com/download/10m/cultural/ne_10m_admin_0_countries.zip'
dfile <- 'ne_10m_admin_0_countries.zip'
download.file(url.c, destfile=dfile, method='wget')
# Unzip Shapefile
unzip('ne_10m_admin_0_countries.zip', exdir='countries')
#Remove .zip file
file.remove('ne_10m_admin_0_countries.zip')
# Read Shapefile of Countries
cshp <- readOGR('countries', 'ne_10m_admin_0_countries')
# Unzip Shapefile
unzip('ne_10m_admin_0_countries.zip', exdir='countries')
#Remove .zip file
file.remove('ne_10m_admin_0_countries.zip')
# Read Shapefile of Countries
cshp <- readOGR('countries', 'ne_10m_admin_0_countries')
cShp <- readOGR('countries', 'ne_10m_admin_0_countries')
dat <- read.csv('UN_Gender-Relations.csv', head=T, sep=';')
setwd("C:/ApplicationInR/worldGenderRatio")
unDat <- read.csv('data/UN_Gender-Relations.csv', head=T, sep=';')
View(unDat)
vDat=cShp@data[,c('WOE_ID','NAME_LONG')]
View(vDat)
rownames(unDat) <- rownames(vDat)
vDat <- cbind(vDat,unDat[,2])
View(vDat)
colname(vDat[,3]) <- 'sex.ratio'
vDat <- cbind(vDat,unDat$Sex.ratio)
vDat <- cShp@data[,c('WOE_ID','NAME_LONG')]
rownames(unDat) <- rownames(vDat)
vDat <- cbind(vDat,unDat$Sex.ratio)
View(vDat)
summary(cShp)
names(vDat)
names(vDat)[3] <- 'sexRatio'
countryShp <- readOGR('countries', 'ne_10m_admin_0_countries')
unData <- read.csv('data/UN_Gender-Relations.csv', head=T, sep=';')
countryShpData <- countryShp@data[,c('WOE_ID','NAME_LONG')]
View(countryShpData)
View(unData)
View(unData)
View(countryShpData)
names(unData)[2] <- 'NAME_LONG'
View(unData)
unData <- read.csv('data/UN_Gender-Relations.csv', head=T, sep=';')
names(unData)[1] <- 'NAME_LONG'
View(unData)
integratedData <- merge(countryShpData, unData[,2], by="NAME_LONG")
integratedData <- merge(countryShpData, unData[,2], by=c("NAME_LONG"))
integratedData <- merge(countryShpData, unData, by=c("NAME_LONG"))
View(integratedData)
integratedData[which(is.na(integratedData[,3])==TRUE) ,3]=' '
View(integratedData)
textOnHover <- c()
textOnHover[which(integratedData[,3]==' ')] <- 'No data provided by UN'
textOnHover[which(integratedData[,3]!=' ')] <- 'Women per 100 men'
integratedData <- cbind(vdat,textOnHover)
integratedData <- cbind(integratedData,textOnHover)
View(integratedData)
colnames(integratedData)=c('COUNTRY','WOE_ID','SEX_RATIO','TEXT_ON_HOVER')
View(integratedData)
library(rgeos)
install.packages("rgeos")
library(rgeos)
countryShpSimplified<-gSimplify(countryShp,tol=0.1, topologyPreserve=TRUE)
spdf=SpatialPolygonsDataFrame(countryShpSimplified, data=integratedData)
countryShpData <- countryShp@data[,c('WOE_ID','NAME_LONG')]
names(unData)[1] <- 'NAME_LONG'
rownames(unDat) <- rownames(countryShpData)
integratedData <- merge(countryShpData, unData, by=c("NAME_LONG"))
rownames(unData) <- rownames(countryShpData)
integratedData <- merge(countryShpData, unData, by=c("NAME_LONG"))
integratedData[which(is.na(integratedData[,3])==TRUE) ,3] <- ' '
textOnHover <- c()
textOnHover[which(integratedData[,3]==' ')] <- 'No data provided by UN'
textOnHover[which(integratedData[,3]!=' ')] <- 'Women per 100 men'
integratedData <- cbind(integratedData,textOnHover)
colnames(integratedData)=c('COUNTRY','WOE_ID','SEX_RATIO','TEXT_ON_HOVER')
# Simplifying shapefile
library(rgeos)
countryShpSimplified<-gSimplify(countryShp,tol=0.1, topologyPreserve=TRUE)
# SpatialPolygonsDataFrame
spdf=SpatialPolygonsDataFrame(countryShpSimplified, data=integratedData)
View(countryShpData)
View(integratedData)
View(countryShpData)
rownames(integratedData) <- rownames(countryShpData)
View(integratedData)
spdf=SpatialPolygonsDataFrame(countryShpSimplified, data=integratedData)
jsfile <- 'leaflet/polygons.js'
if(file.exists(jsfile)){
file.remove(jsfile)
}
writeOGR(spdf, jsfile, layer="", driver="GeoJSON")
writeOGR(spdf, jsfile, layer="", driver="GeoJSON")
library(rgdal)
writeOGR(spdf, jsfile, layer="", driver="GeoJSON")
str(spdf)
writeOGR(spdf, 'dataMap.geojson','dataMap', driver='GeoJSON')
writeOGR(spdf, 'dataMap.geojson', driver='GeoJSON')
writeOGR(spdf, 'dataMap.geojson', layer='dataMap', driver='GeoJSON')
writeOGR(spdf, 'dataMap.geojson', layer='', driver='GeoJSON')
summary(spdf)
geojsonio::geojson_write(spdf, file = jsfile)
install.packages("geojson")
install.packages("geojsonio")
library(geojsonio)
geojsonio::geojson_write(spdf, file = jsfile)
geojsonio::geojson_write(spdf, file = '/geojson/countries.geojson')
getwd()
geojson_write(spdf, file = '/geojson/countries.geojson')
geojson_write(spdf, file = 'C:/ApplicationInR/worldGenderRatio/geojson/countries.geojson')
quit()
